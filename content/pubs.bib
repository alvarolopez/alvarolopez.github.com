% Encoding: UTF-8

@Article{LopezGarcia2017,
  author        = {López García*, Álvaro and Zangrando, Lisa and Sgaravatto, Massimo and Llorens, Vincent and Vallero, Sara and Zaccolo, Valentina and Bagnasco, Stefano and Taneja, Sonia and Pra, Stefano Dal and Salomoni, Davide and Donvito, Giacinto and López García, Alvaro and Zangrando, Lisa and Sgaravatto, Massimo and Llorens, Vincent and Vallero, Sara and Zaccolo, Valentina and Bagnasco, Stefano and Taneja, Sonia and Pra, Stefano Dal and Salomoni, Davide and Donvito, Giacinto},
  title         = {{Improved Cloud resource allocation: how INDIGO-DataCloud is overcoming the current limitations in Cloud schedulers}},
  journal       = {Journal of Physics: Conference Series},
  year          = {2017},
  volume        = {898},
  number        = {9},
  pages         = {92010},
  month         = {7},
  abstract      = {Performing efficient resource provisioning is a fundamental aspect for any resource provider. Local Resource Management Systems (LRMS) have been used in data centers for decades in order to obtain the best usage of the resources, providing their fair usage and partitioning for the users. In contrast, current cloud schedulers are normally based on the immediate allocation of resources on a first-come, first-served basis, meaning that a request will fail if there are no resources (e.g. OpenStack) or it will be trivially queued ordered by entry time (e.g. OpenNebula). Moreover, these scheduling strategies are based on a static partitioning of the resources, meaning that existing quotas cannot be exceeded, even if there are idle resources allocated to other projects. This is a consequence of the fact that cloud instances are not associated with a maximum execution time and leads to a situation where the resources are under-utilized. These facts have been identified by the INDIGO-DataCloud project as being too simplistic for accommodating scientific workloads in an efficient way, leading to an underutilization of the resources, a non desirable situation in scientific data centers. In this work, we will present the work done in the scheduling area during the first year of the INDIGO project and the foreseen evolutions.},
  addendum      = {Journal impact factor (SJR 2016): 0.240},
  archiveprefix = {arXiv},
  arxivid       = {1707.06403},
  doi           = {10.1088/1742-6596/898/9/092010},
  eprint        = {1707.06403},
  file          = {:home/alvaro/Mendeley/Garcia et al. - 2017 - Improved Cloud resource allocation how INDIGO-DataCloud is overcoming the current limitations in Cloud schedulers.pdf:pdf},
  url           = {http://stacks.iop.org/1742-6596/898/i=9/a=092010 http://arxiv.org/abs/1707.06403},
}

@Article{LopezGarcia2017b,
  author    = {Caballer, Miguel and Zala, Sahdev and López García*, Álvaro and Montó, Germán and Orviz Fernández, Pablo and Velten, Mathieu},
  title     = {Orchestrating complex application architectures in heterogeneous clouds},
  journal   = {Journal of Grid Computing},
  year      = {2018},
  volume    = {16},
  number    = {1},
  pages     = {3--18},
  month     = {3},
  issn      = {1570-7873},
  addendum  = {Journal impact factor (JCR 2018): 3.288},
  doi       = {10.1007/s10723-017-9418-y},
  timestamp = {2017.10.23},
}

@Article{LopezGarcia2017c,
  author    = {López García*, Álvaro and Fernández-del-Castillo, Enol and Orviz Fernández, Pablo and Campos Plasencia, Isabel and Marco de Lucas, Jesús},
  title     = {{Resource provisioning in Science Clouds: Requirements and challenges}},
  journal   = {Software: Practice and Experience},
  year      = {2018},
  volume    = {48},
  number    = {3},
  pages     = {486--498},
  month     = {3},
  issn      = {1097-024X},
  note      = {10.1002/spe.2544},
  addendum  = {Journal impact factor (JCR 2019): 1.931},
  doi       = {10.1002/spe.2544},
  keywords  = {cloud challenges, cloud computing, Science Clouds, scientific computing},
  timestamp = {2017.09.25},
  url       = {http://dx.doi.org/10.1002/spe.2544},
}

@Article{LopezGarcia2016,
  author   = {López García*, Álvaro and Fernández del Castillo, Enol and Orviz Fernández, Pablo},
  title    = {{ooi: OpenStack OCCI interface}},
  journal  = {SoftwareX},
  year     = {2016},
  volume   = {5},
  pages    = {6--11},
  month    = {1},
  issn     = {23527110},
  abstract = {In this document we present an implementation of the Open Grid Forum's Open Cloud Computing Interface (OCCI) for OpenStack, namely ooi (Openstack occi interface, 2015) [1]. OCCI is an open standard for management tasks over cloud resources, focused on interoperability, portability and integration. ooi aims to implement this open interface for the OpenStack cloud middleware, promoting interoperability with other OCCI-enabled cloud management frameworks and infrastructures. ooi focuses on being non-invasive with a vanilla OpenStack installation, not tied to a particular OpenStack release version.},
  addendum = {Journal impact factor (CITESCORE 2016): 4.430},
  doi      = {10.1016/j.softx.2016.01.001},
  file     = {:home/alvaro/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/López García, Fernández del Castillo, Orviz Fernández - 2016 - ooi OpenStack OCCI interface.pdf:pdf},
  keywords = {Cloud,Interface,OCCI,Standards,cloud,interface,occi,standards},
  url      = {http://www.sciencedirect.com/science/article/pii/S2352711016000029 http://linkinghub.elsevier.com/retrieve/pii/S2352711016000029},
}

@Article{LopezGarcia2016a,
  Title                    = {Efficient image deployment in cloud environments},
  Author                   = {López García*, Álvaro and Fernández del Castillo, Enol},
  Journal                  = {Journal of Network and Computer Applications},
  Year                     = {2016},

  Month                    = {2},
  Pages                    = {140--149},
  Volume                   = {63},

  Abstract                 = {The biggest overhead for the instantiation of a virtual machine in a cloud infrastructure is the time spent in transferring the image of the virtual machine into the physical node that executes it. This overhead becomes larger for requests composed of several virtual machines to be started concurrently, and the illusion of flexibility and elasticity usually associated with the cloud computing model may vanish. This poses a problem for both the resource providers and the software developers, since tackling those overheads is not a trivial issue. In this work we implement and evaluate several improvements for virtual machine image distribution problem in a cloud infrastructure and propose a method based on BitTorrent and local caching of the virtual machine images that reduces the transfer time when large requests are made.},
  Addendum                 = {Journal impact factor (JCR 2016): 3.500},
  Doi                      = {10.1016/j.jnca.2015.10.015},
  File                     = {:home/alvaro/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/López García, Fernández del Castillo - 2016 - Efficient image deployment in cloud environments.pdf:pdf},
  ISSN                     = {10848045},
  Keywords                 = {Cloud computing,Image deployment,OpenStack,Scheduling},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1084804516000382}
}

@Article{LopezGarcia2016b,
  author    = {López García*, Álvaro and Fernández-del-Castillo, Enol and Orviz Fernández, Pablo},
  title     = {{Standards for enabling heterogeneous IaaS cloud federations}},
  journal   = {Computer Standards \& Interfaces},
  year      = {2016},
  volume    = {47},
  pages     = {19--23},
  month     = {2},
  issn      = {0920-5489},
  abstract  = {Technology market is continuing a rapid growth phase where different resource providers and Cloud Management Frameworks are positioning to provide ad-hoc solutions -in terms of management interfaces, information discovery or billing- trying to differentiate from competitors but that as a result remain incompatible between them when addressing more complex scenarios like federated clouds. Grasping interoperability problems present in current infrastructures is then a must-do, tackled by studying how existing and emerging standards could enhance user experience in the cloud ecosystem. In this paper we will review the current open challenges in Infrastructure as a Service cloud interoperability and federation, as well as point to the potential standards that should alleviate these problems.},
  addendum  = {Journal impact factor (JCR 2016): 1.633},
  doi       = {10.1016/j.csi.2016.02.002},
  file      = {:tmp/1-s2.0-S0920548916300022-main.pdf:pdf},
  keywords  = {,Cloud Computing,Cloud computing,Federation,Interoperability,Standards},
  publisher = {Elsevier B.V.},
  url       = {http://dx.doi.org/10.1016/j.csi.2016.02.002 http://www.sciencedirect.com/science/article/pii/S0920548916300022},
}

@Article{FernandezdelCastillo2015,
  author   = {Fernández-del-Castillo, Enol and Scardaci, Diego and López García, Álvaro},
  title    = {{The EGI Federated Cloud e-Infrastructure}},
  journal  = {Procedia Computer Science},
  year     = {2015},
  volume   = {68},
  pages    = {196--205},
  month    = {10},
  issn     = {18770509},
  abstract = {The EGI Federated Cloud is a standards-based open cloud system that offers a scalable and flexible e-infrastructure to the European research community, and extends the EGI computational offer beyond the traditional High Throughput Computing of the grid plat- form with new models like long-lived services and on demand computation. The EGI Cloud technology enables the federation of institutional clouds to run scientists workloads, simulations and services spanned across multiple administrative locations, allowing the users to access and exploit its resources as a unique system. The architecture of the federation was defined after a two year period of development based on a set of user stories describing operations on a cloud infrascturues and was officially launched in May 2014. Since then the EGI Federated Cloud operates as a federation of heterogeneous Infrastructure as a Service type clouds with every participating provider implementing the same set of interfaces towards users and system administrators. Enforcing cloud technology agnosticism and of supporting service mobility by means of open standards has also allowed for the inclusion of commercial cloud providers into an infrastructure previously supported only by academic institutions. This contributes to a wider goal of the funders to create economic and social impact from supported research activities. This paper details the state of the art, the design and development processes, and the organisational effort that have lead to the creation and deployment of the EGI Cloud Platform.},
  addendum = {Journal impact factor (SJR 2015): 0.310},
  doi      = {10.1016/j.procs.2015.09.235},
  file     = {:home/alvaro/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fernández-del-Castillo, Scardaci, López García - 2015 - The EGI Federated Cloud e-Infrastructure(2).pdf:pdf},
  keywords = {,Cloud Computing,Federation of Resources,cloud computing,e-infrastructure,federation of resources,support},
  url      = {http://www.sciencedirect.com/science/article/pii/S187705091503080X http://linkinghub.elsevier.com/retrieve/pii/S187705091503080X},
}

@Article{Campos2013,
  author        = {Campos Plasencia, Isabel and Fernández-del-Castillo, Enol and Heinemeyer, S. and López García, Álvaro and Pahlen, Federico and Borges, Gonçalo},
  title         = {{Phenomenology tools on cloud infrastructures using OpenStack}},
  journal       = {The European Physical Journal C},
  year          = {2013},
  volume        = {73},
  number        = {4},
  pages         = {2375},
  month         = {4},
  issn          = {1434-6044},
  addendum      = {Journal impact factor (JCR 2013): 5.436},
  archiveprefix = {arXiv},
  arxivid       = {arXiv:1212.4784v1},
  doi           = {10.1140/epjc/s10052-013-2375-0},
  eprint        = {arXiv:1212.4784v1},
  file          = {:home/alvaro/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Campos Plasencia et al. - 2013 - Phenomenology tools on cloud infrastructures using OpenStack(7).pdf:pdf;:home/alvaro/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Campos Plasencia et al. - 2013 - Phenomenology tools on cloud infrastructures using OpenStack(8).pdf:pdf;:home/alvaro/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Campos Plasencia et al. - 2013 - Phenomenology tools on cloud infrastructures using OpenStack(9).pdf:pdf},
  isbn          = {1005201323},
  url           = {http://link.springer.com/10.1140/epjc/s10052-013-2375-0},
}

@Article{Borges2012,
  author   = {Borges, Gonçalo and David, Mario and Gomes, Hugo and Gomes, Jorge and Martins, Jo\~ao and Pina, Jo\~ao Murta and Blanquer, Ignacio and Arce, David and Caballer, Miguel and López García, Álvaro and Orviz Fernández, Pablo and Plasencia, Isabel Campos and Marco de Lucas, Jesús and Simón García, Álvaro},
  title    = {{Fostering Multi-Scientific Usage in the Iberian Production Infrastructure}},
  journal  = {Computing and Informatics},
  year     = {2012},
  volume   = {31},
  number   = {1},
  pages    = {61--72},
  issn     = {1335-9150},
  addendum = {Journal impact factor (JCR 2012): 0.254},
  file     = {:home/alvaro/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Borges et al. - 2012 - Fostering Multi-Scientific Usage in the Iberian Production Infrastructure.pdf:pdf},
  url      = {http://dblp.uni-trier.de/db/journals/cai/cai31.html\#BorgesDGGMPBACLOCMS12},
}

@Article{DopazoRosende2012,
  author  = {{Dopazo Rosende}, Roberto and {Simón García}, Alvaro and {García Freire}, Esteban and {Fernández Sánchez}, Carlos and López García, Álvaro and Orviz Fernández, Pablo and Fernández-del-Castillo, Enol and Borges, Gonçalo},
  title   = {{Grid Engine batch system integration in the EMI era}},
  journal = {Proceedings of Science},
  year    = {2012},
  volume  = {EGICF12-EM},
  file    = {:home/alvaro/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dopazo Rosende et al. - 2012 - Grid Engine batch system integration in the EMI era.pdf:pdf},
  url     = {http://adsabs.harvard.edu/abs/2012egic.confE..83R},
}

@Article{lpezgarca2012,
  author   = {David, M. and Borges, G. and Gomes, J. and Pina, J. and Campos, I. and Fernandez, E. and López García, Álvaro and Orviz, P. and Cacheiro, J.L. and Fernandez, C. and Simon, A. and Fernandez, A.},
  title    = {{Software provision process for EGI}},
  journal  = {Computing and Informatics},
  year     = {2012},
  volume   = {31},
  number   = {1},
  pages    = {135-148},
  issn     = {1335-9150},
  addendum = {Journal impact factor (JCR 2012): 0.254},
}

@Article{Rodriguez-Marrero2012,
  author   = {Rodríguez-Marrero, Ana Yaiza and González Caballero, Isidro and Cuesta Noriega, Alberto and Fernández-del-Castillo, Enol and López García, Álvaro and Marco de Lucas, Jesús and Matorras Weinig, Francisco},
  title    = {{Integrating PROOF Analysis in Cloud and Batch Clusters}},
  journal  = {Journal of Physics: Conference Series},
  year     = {2012},
  volume   = {396},
  number   = {3},
  pages    = {32091},
  month    = {12},
  issn     = {1742-6588},
  addendum = {Journal impact factor (SJR 2012): 0.28},
  doi      = {10.1088/1742-6596/396/3/032091},
  file     = {:home/alvaro/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rodríguez-Marrero et al. - 2012 - Integrating PROOF Analysis in Cloud and Batch Clusters(4).pdf:pdf},
  url      = {http://stacks.iop.org/1742-6596/396/i=3/a=032091?key=crossref.a4219812d32b8f4fb9c750e66cfcde37},
}

@InCollection{Borges2010,
  author    = {Borges, Gonçalo and Gomes, Jorge and Montecelo, Manuel and David, Mario and Silva, B. and Dias, N. and Martins, J. P. and {Fernández Sánchez}, Carlos and García-Tarres, L. and Veiga, C. and Cordero, D. and López-Cacheiro, Javier and Marco de Lucas, Jesús and Campos Plasencia, Isabel and Rodríguez, D and Marco, R and López García, Álvaro and Orviz Fernández, Pablo and Hammad, A. and Hardt, M. and Fernández-del-Castillo, Enol and Heymann, E. and Senar, M.A and Padee, A. and Nawrocki, K. and Wislicki, W. and Heinzlreiter, P. and Baumgartner, M. and Rosmanith, H. and Kenny, S. and Coghlan, B. and Lason, P. and Skital, L. and Astalos, J. and Ciglan, M. and Pospieszny, M. and Valles, R. and Dichev, K.},
  title     = {{Int.eu.grid}},
  booktitle = {Remote Instrumentation and Virtual Laboratories},
  publisher = {Springer},
  year      = {2010},
  editor    = {Davoli, Franco and Meyer, Norbert and Pugliese, Roberto and Zappatore, S},
  pages     = {201--210},
  isbn      = {978-1-4419-5595-1},
}

@Article{780,
  author   = {Gomes, Jorge and Borges, Gonçalo and Montecelo, Manuel and David, Mario and Silva, B and Dias, N and Martins, J. P. and {Fernández Sánchez}, Carlos and García-Tarres, L. and Veiga, C. and Cordero, D. and López-Cacheiro, Javier and Marco de Lucas, Jesús and Campos Plasencia, Isabel and Rodríguez, D and Marco, R and López García, Álvaro and Orviz Fernández, Pablo and Hammad, A.},
  title    = {{A Grid infrastructure for parallel and interactive applications}},
  journal  = {Computing and Informatics},
  year     = {2008},
  volume   = {27},
  number   = {2},
  pages    = {173--185},
  issn     = {1335-9150},
  abstract = {The int.eu.grid project aims at providing a production quality grid computing infrastructure for e-Science supporting parallel and interactive applications. The infrastructure capacity is presently about 750 cpu cores distributed over twelve sites in seven countries. These resources have to be tightly coordinated to match the requirements of parallel computing. Such an infrastructure implies high availability, performance and robustness resulting in a much larger management effort than in traditional grid environments which are usually targeted to run sequential non-interactive applications. To achieve these goals the int.eu.grid project offers advanced brokering mechanisms and user friendly graphical interfaces supporting application steering. The int.eu.grid environment is deployed on top of the gLite middleware enabling full interoperability with existing gLite based infrastructures.},
  addendum = {Journal impact factor (JCR 2008): 0.492},
  chapter  = {173},
  file     = {:home/alvaro/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gomes et al. - 2008 - A Grid infrastructure for parallel and interactive applications.pdf:pdf},
  keywords = {Grid computing,inte,interactivity,parallel jobs},
  url      = {http://www.cai.sk/ojs/index.php/cai/article/view/259/210},
}

@Article{782,
  author   = {Marco de Lucas, Jesús and Campos Plasencia, Isabel and Coterillo, I and Diaz, I and López García, Álvaro and Marco, R and Martinez-Rivero, C and Orviz Fernández, Pablo and Rodríguez, D and Gomes, Jorge and Borges, Gonçalo and Montecelo, Manuel and David, Mario and Silva, B and Dias, N and Martins, J. P. and {Fernández Sánchez}, Carlos and García-Tarres, L.},
  title    = {{The interactive European Grid: Project objectives and achievements}},
  journal  = {Computing and Informatics},
  year     = {2008},
  volume   = {27},
  number   = {2},
  pages    = {161--171},
  issn     = {1335-9150},
  addendum = {Journal impact factor (JCR 2008): 0.492},
  chapter  = {161},
  file     = {:home/alvaro/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Marco de Lucas et al. - 2008 - The interactive European Grid Project objectives and achievements.pdf:pdf},
}

@Article{Collaboration2008,
  author   = {{The CMS Collaboration}},
  title    = {{The CMS experiment at the CERN LHC}},
  journal  = {Journal of Instrumentation},
  year     = {2008},
  volume   = {3},
  number   = {08},
  pages    = {S08004--S08004},
  month    = {8},
  issn     = {1748-0221},
  abstract = {The Compact Muon Solenoid (CMS) detector is described. The detector operates at the Large Hadron Collider (LHC) at CERN. It was conceived to study proton-proton (and lead-lead) collisions at a centre-of-mass energy of 14 TeV (5.5 TeV nucleon-nucleon) and at luminosities up to 10 34 cm −2 s −1 (10 27 cm −2 s −1 ). At the core of the CMS detector sits a high-magnetic-field and large-bore superconducting solenoid surrounding an all-silicon pixel and strip tracker, a lead-tungstate scintillating-crystals electromagnetic calorimeter, and a brass-scintillator sampling hadron calorimeter. The iron yoke of the flux-return is instrumented with four stations of muon detectors covering most of the 4$\pi$ solid angle. Forward sampling calorimeters extend the pseudorapidity coverage to high values (|$\eta$| ≤ 5) assuring very good hermeticity. The overall dimensions of the CMS detector are a length of 21.6 m, a diameter of 14.6 m and a total weight of 12500 t.},
  addendum = {Journal impact factor (JCR 2008): 0.821},
  doi      = {10.1088/1748-0221/3/08/S08004},
  file     = {:home/alvaro/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Collaboration et al. - 2008 - The CMS experiment at the CERN LHC.pdf:pdf},
  url      = {http://stacks.iop.org/1748-0221/3/i=08/a=S08004},
}

@Article{LopezGarcia2007,
  author   = {López García*, Álvaro and Mariotti, Mirko and Salomoni, Davide and Servoli, Leonello},
  title    = {{A high availability solution for GRID services}},
  journal  = {Proceedings of Science},
  year     = {2007},
  volume   = {ACAT},
  pages    = {13},
  file     = {:home/alvaro/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/López García et al. - 2007 - A high availability solution for GRID services(2).pdf:pdf},
  keywords = {virtualization},
  url      = {citeulike-article-id:9146151},
}

@Article{Salomoni2018,
  author    = {Salomoni, D. and Campos, I. and Gaido, L. and de Lucas, J. Marco and Solagna, P. and Gomes, J. and Matyska, L. and Fuhrman, P. and Hardt, M. and Donvito, G. and Dutka, L. and Plociennik, M. and Barbera, R. and Blanquer, I. and Ceccanti, A. and Cetinic, E. and David, M. and Duma, C. and L{\'o}pez-Garc{\'i}a, A. and Molt{\'o}, G. and Orviz, P. and Sustr, Z. and Viljoen, M. and Aguilar, F. and Alves, L. and Antonacci, M. and Antonelli, L. A. and Bagnasco, S. and Bonvin, A. M. J. J. and Bruno, R. and Chen, Y. and Costa, A. and Davidovic, D. and Ertl, B. and Fargetta, M. and Fiore, S. and Gallozzi, S. and Kurkcuoglu, Z. and Lloret, L. and Martins, J. and Nuzzo, A. and Nassisi, P. and Palazzo, C. and Pina, J. and Sciacca, E. and Spiga, D. and Tangaro, M. and Urbaniak, M. and Vallero, S. and Wegh, B. and Zaccolo, V. and Zambelli, F. and Zok, T.},
  title     = {{INDIGO-DataCloud: a Platform to Facilitate Seamless Access to E-Infrastructures}},
  journal   = {Journal of Grid Computing},
  year      = {2018},
  month     = {8},
  issn      = {1572-9184},
  abstract  = {This paper describes the achievements of the H2020 project INDIGO-DataCloud. The project has provided e-infrastructures with tools, applications and cloud framework enhancements to manage the demanding requirements of scientific communities, either locally or through enhanced interfaces. The middleware developed allows to federate hybrid resources, to easily write, port and run scientific applications to the cloud. In particular, we have extended existing PaaS (Platform as a Service) solutions, allowing public and private e-infrastructures, including those provided by EGI, EUDAT, and Helix Nebula, to integrate their existing services and make them available through AAI services compliant with GEANT interfederation policies, thus guaranteeing transparency and trust in the provisioning of such services. Our middleware facilitates the execution of applications using containers on Cloud and Grid based infrastructures, as well as on HPC clusters. Our developments are freely downloadable as open source components, and are already being integrated into many scientific applications.},
  addendum  = {Journal impact factor (JCR 2018): 3.288},
  day       = {07},
  doi       = {10.1007/s10723-018-9453-3},
  owner     = {alvaro},
  timestamp = {2018.08.10},
  url       = {https://doi.org/10.1007/s10723-018-9453-3},
}

@Article{GOMES201884,
  author   = {Jorge Gomes and Emanuele Bagnaschi and Isabel Campos and Mario David and Luís Alves and João Martins and João Pina and Alvaro López-García and Pablo Orviz},
  title    = {{Enabling rootless Linux Containers in multi-user environments: The udocker tool}},
  journal  = {Computer Physics Communications},
  year     = {2018},
  volume   = {232},
  pages    = {84--97},
  issn     = {0010-4655},
  addendum = {Journal impact factor (JCR 2018): 3.309},
  doi      = {10.1016/j.cpc.2018.05.021},
  keywords = {Linux containers, HPC on cloud, Virtualization, Phenomenology, QCD, Biophysics},
  url      = {http://www.sciencedirect.com/science/article/pii/S0010465518302042},
}

@Article{OrvizFernandez2018,
  author    = {Orviz Fern{\'a}ndez, Pablo and Pina, Jo{\~a}o and L{\'o}pez Garc{\'i}a, {\'A}lvaro and Campos Plasencia, Isabel and David, M{\'a}rio and Gomes, Jorge},
  title     = {umd-verification: Automation of Software Validation for the EGI Federated e-Infrastructure},
  journal   = {Journal of Grid Computing},
  year      = {2018},
  volume    = {16},
  number    = {4},
  pages     = {683–696},
  month     = {Dec},
  issn      = {1572-9184},
  abstract  = {Supporting e-Science in the EGI e-Infrastructure requires extensive and reliable software, for advanced computing use, deployed across over approximately 300 European and worldwide data centers. The Unified Middleware Distribution (UMD) and Cloud Middleware Distribution (CMD) are the channels to deliver the software for the EGI e-Infrastructure consumption. The software is compiled, validated and distributed following the Software Provisioning Process (SWPP), where the Quality Criteria (QC) definition sets the minimum quality requirements for EGI acceptance. The growing number of software components currently existing within UMD and CMD distributions hinders the application of the traditional, manual-based validation mechanisms, thus driving the adoption of automated solutions. This paper presents umd-verification, an open-source tool that enforces the fulfillment of the QC requirements in an automated way for the continuous validation of the software products for scientific disposal. The umd-verification tool has been successfully integrated within the SWPP pipeline and is progressively supporting the full validation of the products in the UMD and CMD repositories. While the cost of supporting new products is dependant on the availability of Infrastructure as Code solutions to take over the deployment and high test coverage, the results obtained for the already integrated products are promising, as the time invested in the validation of products has been drastically reduced. Furthermore, automation adoption has brought along benefits for the reliability of the process, such as the removal of human-associated errors or the risk of regression of previously tested functionalities.},
  addendum  = {Journal impact factor (JCR 2018): 3.288},
  day       = {1},
  doi       = {10.1007/s10723-018-9454-2},
  owner     = {alvaro},
  timestamp = {2018.08.14},
  url       = {https://doi.org/10.1007/s10723-018-9454-2},
}

@Article{LopezGarcia2019,
  author    = {López García*, Álvaro and Fernández del Castillo, Enol and Campos Plasencia, Isabel},
  title     = {An efficient cloud scheduler design supporting preemptible instances},
  journal   = {Future Generation Computer Systems},
  year      = {2019},
  volume    = {95},
  pages     = {68 - 78},
  issn      = {0167-739X},
  abstract  = {Maximizing resource utilization by performing an efficient resource provisioning is a key factor for any cloud provider: commercial actors can maximize their revenues, whereas scientific and non-commercial providers can maximize their infrastructure utilization. Traditionally, batch systems have allowed data centers to fill their resources as much as possible by using backfilling and similar techniques. However, in an IaaS cloud, where virtual machines are supposed to live indefinitely, or at least as long as the user is able to pay for them, these policies are not easily implementable. In this work we present a new scheduling algorithm for IaaS providers that is able to support preemptible instances, that can be stopped by higher priority requests without introducing large modifications in the current cloud schedulers. This scheduler enables the implementation of new cloud usage and payment models that allow more efficient usage of the resources and potential new revenue sources for commercial providers. We also study the correctness and the performance overhead of the proposed scheduler against existing solutions.},
  addendum  = {Journal impact factor (JCR 2019): 6.125},
  doi       = {10.1016/j.future.2018.12.057},
  keywords  = {Cloud computing, Scheduling, Preemptible instances, Spot instances, Resource allocation},
  owner     = {alvaro},
  timestamp = {2019.01.14},
  url       = {http://www.sciencedirect.com/science/article/pii/S0167739X1830270X},
}

@Article{Nguyen2019,
  author   = {Nguyen, Giang and Dlugolinsky, Stefan and Bob{\'a}k, Martin and Tran, Viet and L{\'o}pez Garc{\'i}a, {\'A}lvaro and Heredia, Ignacio and Mal{\'i}k, Peter and Hluch{\'y}, Ladislav},
  title    = {Machine Learning and Deep Learning frameworks and libraries for large-scale data mining: a survey},
  journal  = {Artificial Intelligence Review},
  year     = {2019},
  volume   = {52},
  number   = {1},
  pages    = {77--124},
  month    = {Jun},
  issn     = {1573-7462},
  abstract = {The combined impact of new computing resources and techniques with an increasing avalanche of large datasets, is transforming many research areas and may lead to technological breakthroughs that can be used by billions of people. In the recent years, Machine Learning and especially its subfield Deep Learning have seen impressive advances. Techniques developed within these two fields are now able to analyze and learn from huge amounts of real world examples in a disparate formats. While the number of Machine Learning algorithms is extensive and growing, their implementations through frameworks and libraries is also extensive and growing too. The software development in this field is fast paced with a large number of open-source software coming from the academy, industry, start-ups or wider open-source communities. This survey presents a recent time-slide comprehensive overview with comparisons as well as trends in development and usage of cutting-edge Artificial Intelligence software. It also provides an overview of massive parallelism support that is capable of scaling computation effectively and efficiently in the era of Big Data.},
  addendum = {Journal impact factor (JCR 2018): 5.747},
  day      = {01},
  doi      = {10.1007/s10462-018-09679-z},
  url      = {https://doi.org/10.1007/s10462-018-09679-z},
}

@Article{refId0,
  author    = {Spiga, Daniele and Antonacci, Marica and Boccali, Tommaso and Ceccanti, Andrea and Ciangottini, Diego and Di Maria, Riccardo and Donvito, Giacinto and Duma, Cristina and Gaido, Luciano and L\'opez Garc{\'i}a, \'Alvaro and Palacio Hoz, Aida and Salomoni, Davide and Tracolli, Mirco},
  title     = {Exploiting private and commercial clouds to generate on-demand CMS computing facilities with DODAS},
  journal   = {EPJ Web Conf.},
  year      = {2019},
  volume    = {214},
  pages     = {07027},
  doi       = {10.1051/epjconf/201921407027},
  owner     = {alvaro},
  timestamp = {2019.09.17},
  url       = {https://doi.org/10.1051/epjconf/201921407027},
}

@Article{Lopez2019DEEPaaS,
  author    = {López García*, Álvaro},
  title     = {DEEPaaS API: a REST API for Machine Learning and Deep Learning models},
  journal   = {Journal of Open Source Software},
  year      = {2019},
  volume    = {4},
  number    = {42},
  pages     = {1517},
  month     = {10},
  issn      = {2475-9066},
  date      = {2019-10-25},
  day       = {25},
  doi       = {10.21105/joss.01517},
  owner     = {alvaro},
  publisher = {The Open Journal},
  timestamp = {2019.11.14},
  url       = {http://dx.doi.org/10.21105/joss.01517},
}

@Article{Castrillo2020,
  author    = {Castrillo Melguizo, María and López García, Álvaro},
  title     = {Estimation of high frequency nutrient concentrations from water quality surrogates using machine learning methods},
  journal   = {Water Research},
  year      = {2020},
  volume    = {172},
  pages     = {115490},
  issn      = {0043-1354},
  addendum  = {Journal impact factor (JCR 2020): 11.236},
  doi       = {10.1016/j.watres.2020.115490},
  keywords  = {Water monitoring, Water quality, Surrogate parameters, Random forests, Soft-sensors, Machine learning},
  owner     = {alvaro},
  timestamp = {2020.10.01},
  url       = {http://www.sciencedirect.com/science/article/pii/S0043135420300269},
}

@Article{8966259,
  author   = {G. {Nguyen} and S. {Dlugolinsky} and V. {Tran} and López García, Álvaro},
  title    = {Deep Learning for Proactive Network Monitoring and Security Protection},
  journal  = {IEEE Access},
  year     = {2020},
  volume   = {8},
  pages    = {19696-19716},
  addendum = {Journal impact factor (JCR 2020): 3.367},
  doi      = {10.1109/ACCESS.2020.2968718},
}

@Article{8950411,
  author   = {López García*, Álvaro and J. {Marco de Lucas} and M. {Antonacci} and W. {Zu Castell} and M. {David} and M. {Hardt} and L. {Lloret Iglesias} and G. {Moltó} and M. {Plociennik} and V. {Tran} and A. S. {Alic} and M. {Caballer} and I. C. {Plasencia} and A. {Costantini} and S. {Dlugolinsky} and D. C. {Duma} and G. {Donvito} and J. {Gomes} and I. {Heredia Cacha} and K. {Ito} and V. Y. {Kozlov} and G. {Nguyen} and P. {Orviz Fernández} and Z. {Šustr} and P. {Wolniewicz}},
  title    = {A Cloud-Based Framework for Machine Learning Workloads and Applications},
  journal  = {IEEE Access},
  year     = {2020},
  volume   = {8},
  pages    = {18681-18692},
  addendum = {Journal impact factor (JCR 2020): 3.367},
  doi      = {10.1109/ACCESS.2020.2964386},
}

@Article{Gonzalez-Abad2022,
  author   = {González-Abad, Jose and López García, Álvaro and Kozlov, Valentin Y.},
  title    = {A container-based workflow for distributed training of deep learning algorithms in HPC clusters},
  journal  = {Cluster Computing},
  year     = {2022},
  month    = nov,
  issn     = {1573-7543},
  abstract = {Deep learning has been postulated as a solution for numerous problems in different branches of science. Given the resource-intensive nature of these models, they often need to be executed on specialized hardware such graphical processing units (GPUs) in a distributed manner. In the academic field, researchers get access to this kind of resources through High Performance Computing (HPC) clusters. This kind of infrastructures make the training of these models difficult due to their multi-user nature and limited user permission. In addition, different HPC clusters may possess different peculiarities that can entangle the research cycle (e.g., libraries dependencies). In this paper we develop a workflow and methodology for the distributed training of deep learning models in HPC clusters which provides researchers with a series of novel advantages. It relies on udocker as containerization tool and on Horovod as library for the distribution of the models across multiple GPUs. udocker does not need any special permission, allowing researchers to run the entire workflow without relying on any administrator. Horovod ensures the efficient distribution of the training independently of the deep learning framework used. Additionally, due to containerization and specific features of the workflow, it provides researchers with a cluster-agnostic way of running their models. The experiments carried out show that the workflow offers good scalability in the distributed training of the models and that it easily adapts to different clusters.},
  addendum = {Journal impact factor (JCR 2021): 2.303},
  doi      = {10.1007/s10586-022-03798-7},
  refid    = {González-Abad2022},
}

@Article{Sainz-PardoDiaz2023,
  author   = {Sáinz-Pardo Díaz, Judith and López García, Álvaro},
  title    = {Study of the performance and scalability of federated learning for medical imaging with intermittent clients},
  journal  = {Neurocomputing},
  year     = {2023},
  volume   = {518},
  pages    = {142--154},
  month    = jan,
  issn     = {0925-2312},
  abstract = {Federated learning is a data decentralization privacy-preserving technique used to perform machine or deep learning in a secure way. In this paper we present theoretical aspects about federated learning, such as the presentation of an aggregation operator, different types of federated learning, and issues to be taken into account in relation to the distribution of data from the clients, together with the exhaustive analysis of a use case where the number of clients varies. Specifically, a use case of medical image analysis is proposed, using chest X-ray images obtained from an open data repository. In addition to the advantages related to privacy, improvements in predictions (in terms of accuracy, loss and area under the curve) and reduction of execution times will be studied with respect to the classical case (the centralized approach). Different clients will be simulated from the training data, selected in an unbalanced manner. The results of considering three or ten clients are exposed and compared between them and against the centralized case. Two different problems related to intermittent clients are discussed, together with two approaches to be followed for each of them. Specifically, this type of problems may occur because in a real scenario some clients may leave the training, and others enter it, and on the other hand because of client technical or connectivity problems. Finally, improvements and future work in the field are proposed.},
  addendum = {Journal impact factor (JCR 2022): 6.0},
  doi      = {10.1016/j.neucom.2022.11.011},
  keywords = {Federated learning, Deep learning, Data decentralization, Data privacy},
  url      = {https://www.sciencedirect.com/science/article/pii/S0925231222013844},
}

@Article{SainzPardo2020,
  author   = {Sáinz-Pardo Díaz, Judith and López García, Álvaro},
  title    = {A Python library to check the level of anonymity of a dataset},
  journal  = {Scientific Data},
  year     = {2022},
  volume   = {9},
  number   = {1},
  pages    = {785},
  month    = dec,
  issn     = {2052-4463},
  abstract = {Openly sharing data with sensitive attributes and privacy restrictions is a challenging task. In this document we present the implementation of pyCANON, a Python library and command line interface (CLI) to check and assess the level of anonymity of a dataset through some of the most common anonymization techniques: k-anonymity, (α,k)-anonymity, ℓ-diversity, entropy ℓ-diversity, recursive (c,ℓ)-diversity, t-closeness, basic β-likeness, enhanced β-likeness and δ-disclosure privacy. For the case of more than one sensitive attribute, two approaches are proposed for evaluating these techniques. The main strength of this library is to obtain a full report of the parameters that are fulfilled for each of the techniques mentioned above, with the unique requirement of the set of quasi-identifiers and sensitive attributes. The methods implemented are presented together with the attacks they prevent, the description of the library, examples of the different functions’ usage, as well as the impact and the possible applications that can be developed. Finally, some possible aspects to be incorporated in future updates are proposed.},
  doi      = {10.1038/s41597-022-01894-2},
  refid    = {Sáinz-Pardo Díaz2022},
}

@Article{HerediaCacha2023,
  author        = {Heredia Cacha, Ignacio and Sáinz-Pardo Díaz, Judith and Castrillo, María and López García*, Álvaro},
  title         = {Forecasting COVID-19 spreading through an ensemble of classical and machine learning models: Spain’s case study},
  journal       = {Scientific Reports},
  year          = {2023},
  volume        = {13},
  number        = {1},
  pages         = {6750},
  month         = apr,
  issn          = {2045-2322},
  __markedentry = {[alvaro:]},
  abstract      = {In this work the applicability of an ensemble of population and machine learning models to predict the evolution of the COVID-19 pandemic in Spain is evaluated, relying solely on public datasets. Firstly, using only incidence data, we trained machine learning models and adjusted classical ODE-based population models, especially suited to capture long term trends. As a novel approach, we then made an ensemble of these two families of models in order to obtain a more robust and accurate prediction. We then proceed to improve machine learning models by adding more input features: vaccination, human mobility and weather conditions. However, these improvements did not translate to the overall ensemble, as the different model families had also different prediction patterns. Additionally, machine learning models degraded when new COVID variants appeared after training. We finally used Shapley Additive Explanation values to discern the relative importance of the different input features for the machine learning models’ predictions. The conclusion of this work is that the ensemble of machine learning models and population models can be a promising alternative to SEIR-like compartmental models, especially given that the former do not need data from recovered patients, which are hard to collect and generally unavailable.},
  addendum      = {Journal impact factor (JCR 2022): 4.6},
  doi           = {10.1038/s41598-023-33795-8},
  refid         = {Heredia Cacha2023},
  url           = {https://doi.org/10.1038/s41598-023-33795-8},
}

@Article{Sainz-PardoDiaz2023a,
  author        = {Judith {Sáinz-Pardo Díaz} and María Castrillo and Álvaro {López García}},
  title         = {Deep learning based soft-sensor for continuous chlorophyll estimation on decentralized data},
  journal       = {Water Research},
  year          = {2023},
  volume        = {246},
  pages         = {120726},
  issn          = {0043-1354},
  __markedentry = {Journal impact factor (JCR 2022): 12.8},
  abstract      = {Monitoring the concentration of pigments like chlorophyll (Chl) in water-bodies is a key task to contribute to their conservation. However, with the existing sensor technology, measurement in real-time and with enough frequency to ensure proper risk management is not completely feasible. In this work, with the concept of data-driven soft-sensing, three hydrophysical features are used together with three meteorological ones to estimate the concentration of Chl in two tributaries of the River Thames. Data driven models, specifically neural networks, are used with three learning approaches: individual, centralized and federated. Data reduction scenarios are proposed in order to analyze the performance of each approach when less data is available. The best results in the training are usually obtained with the individual approach. However, the federated learning provides better generalization ability. It was also observed that in most of the cases the results of the federated learning approach improve those of the centralized one.},
  doi           = {https://doi.org/10.1016/j.watres.2023.120726},
  keywords      = {Chlorophyll monitoring, Water quality, Soft sensor, Deep learning, Federated learning},
  url           = {https://www.sciencedirect.com/science/article/pii/S0043135423011661},
}

@Comment{jabref-meta: databaseType:bibtex;}
